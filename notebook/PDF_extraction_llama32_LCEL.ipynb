{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f407d757",
      "metadata": {
        "id": "f407d757",
        "papermill": {
          "duration": 0.022555,
          "end_time": "2023-11-07T23:40:10.609309",
          "exception": false,
          "start_time": "2023-11-07T23:40:10.586754",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "09ea9d7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:10.558175Z",
          "iopub.status.busy": "2023-11-07T23:40:10.55769Z",
          "iopub.status.idle": "2023-11-07T23:40:10.562952Z",
          "shell.execute_reply": "2023-11-07T23:40:10.561864Z"
        },
        "id": "09ea9d7c",
        "papermill": {
          "duration": 0.030688,
          "end_time": "2023-11-07T23:40:10.565135",
          "exception": false,
          "start_time": "2023-11-07T23:40:10.534447",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "import glob\n",
        "import json\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a39dfc3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/19/25, 10:19 PM Richard Hendriks\n",
            "richard.hendriks@mail.com\n",
            "Richard Hendriks\n",
            "http://richardhendricks.example.com\n",
            "San Francisco, California\n",
            "SUMMARY\n",
            "Richard hails from Tulsa. He has earned degrees from the University of Oklahoma and Stanford. (Go Sooners and\n",
            "Cardinal!) Before starting Pied Piper, he worked for Hooli as a part time software developer. While his work focuses on\n",
            "applied information theory, mostly optimizing lossless compression schema of both the length-limited and adaptive\n",
            "variants, his non-work interests range widely, everything from quantum computing to chaos theory. He could tell you about\n",
            "it, but THAT would NOT be a “length-limited” conversation!\n",
            "SKILLS AND TECH\n",
            "Web Development: HTML, CSS, Javascript.\n",
            "Compression: Mpeg, MP4, GIF.\n",
            "EXPERIENCE\n",
            "Pied Piper CEO/President Dec 2013 — Dec 2014\n",
            "Build an algorithm for artist to detect if their music was violating copy right infringement laws\n",
            "Successfully won Techcrunch Disrupt\n",
            "Optimized an algorithm that holds the current world record for Weisman Scores\n",
            "VOLUNTEERING\n",
            "CoderDojo Teacher Jan 2012 — Jan 2013\n",
            "Awarded 'Teacher of the Month'\n",
            "PROJECTS\n",
            "Miss Direction: Won award at AIHacks 2016. Built by all women team of newbie programmers. Using modern\n",
            "technologies such as GoogleMaps, Chrome Extension and Javascript.\n",
            "EDUCATION\n",
            "University of Oklahoma Jun 2011 — Jan 2014\n",
            "Bachelor - Information Technology, GPA: 4.0\n",
            "PUBLICATIONS\n",
            "Video compression for 3d media Oct 2014\n",
            "AWARDS\n",
            "Digital Compression Pioneer Award, Techcrunch Nov 2014\n",
            "INTERESTS\n",
            "Wildlife: Ferrets, Unicorns\n",
            "https://slugstack.github.io/jsonresume-theme-straightforward/ 1/1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pdf_path = '../data/Richard Hendriks.pdf' # as agreed in whatsapp\n",
        "\n",
        "pdf_text = ''\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            pdf_text += page_text + '\\n'\n",
        "\n",
        "print(pdf_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e9cdec9",
      "metadata": {},
      "source": [
        "# Use regex to break the text into sections\n",
        "## LLM can be used but would be too slow for the demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b26a27a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/19/25, 10:19 PM Richard Hendriks\n",
            "richard.hendriks@mail.com\n",
            "Richard Hendriks\n",
            "http://richardhendricks.example.com\n",
            "San Francisco, California\n",
            "SUMMARY\n",
            "Richard hails from Tulsa. He has earned degrees from the University of Oklahoma and Stanford. (Go Sooners and\n",
            "Cardinal!) Before starting Pied Piper, he worked for Hooli as a part time software developer. While his work focuses on\n",
            "applied information theory, mostly optimizing lossless compression schema of both the length-limited and adaptive\n",
            "variants, his non-work interests range widely, everything from quantum computing to chaos theory. He could tell you about\n",
            "it, but THAT would NOT be a “length-limited” conversation!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'SUMMARY' section from the resume text by grabbing everything from the beginning up to 'SKILLS AND TECH'\n",
        "basics_extracted = pdf_text.split('SKILLS AND TECH')[0]\n",
        "print(basics_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "fce11ff6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Web Development: HTML, CSS, Javascript.\n",
            "Compression: Mpeg, MP4, GIF.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'SKILLS AND TECH' section from the resume text by grabbing everything from 'SKILLS AND TECH' to 'EXPERIENCE'\n",
        "skills_extracted = pdf_text.split('EXPERIENCE')[0].split('SKILLS AND TECH')[1]\n",
        "print(skills_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7316336c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pied Piper CEO/President Dec 2013 — Dec 2014\n",
            "Build an algorithm for artist to detect if their music was violating copy right infringement laws\n",
            "Successfully won Techcrunch Disrupt\n",
            "Optimized an algorithm that holds the current world record for Weisman Scores\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'EXPERIENCE' section from the resume text by grabbing everything from 'EXPERIENCE' to 'VOLUNTEERING'\n",
        "work_extracted = pdf_text.split('VOLUNTEERING')[0].split('EXPERIENCE')[1]\n",
        "print(work_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "4a84e456",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Miss Direction: Won award at AIHacks 2016. Built by all women team of newbie programmers. Using modern\n",
            "technologies such as GoogleMaps, Chrome Extension and Javascript.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'PROJECTS' section from the resume text by grabbing everything from 'PROJECTS' to 'EDUCATION'\n",
        "projects_extracted = pdf_text.split('EDUCATION')[0].split('PROJECTS')[1]\n",
        "print(projects_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "22234406",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "University of Oklahoma Jun 2011 — Jan 2014\n",
            "Bachelor - Information Technology, GPA: 4.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'EDUCATION' section from the resume text by grabbing everything from 'EDUCATION' to 'PUBLICATIONS'\n",
        "education_extracted = pdf_text.split('PUBLICATIONS')[0].split('EDUCATION')[1]\n",
        "print(education_extracted)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "708820c5",
      "metadata": {
        "id": "708820c5",
        "papermill": {
          "duration": 0.034723,
          "end_time": "2023-11-07T23:40:40.687547",
          "exception": false,
          "start_time": "2023-11-07T23:40:40.652824",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## LANGCHAIN\n",
        "\n",
        "### Using the new LCEL Architecture from LangChain.\n",
        "LangChain recommends using LCEL (LangChain Expression Language) over Chains. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da545337",
      "metadata": {
        "id": "da545337",
        "papermill": {
          "duration": 0.035218,
          "end_time": "2023-11-07T23:40:42.330255",
          "exception": false,
          "start_time": "2023-11-07T23:40:42.295037",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Now we create the retriever object, the responsible to return the data contained in the ChromaDB Database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e2267b3d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting huggingface_hub==0.26.0\n",
            "  Using cached huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub==0.26.0) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub==0.26.0) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub==0.26.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub==0.26.0) (6.0.2)\n",
            "Requirement already satisfied: requests in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub==0.26.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub==0.26.0) (4.67.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub==0.26.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests->huggingface_hub==0.26.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests->huggingface_hub==0.26.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests->huggingface_hub==0.26.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests->huggingface_hub==0.26.0) (2024.12.14)\n",
            "Using cached huggingface_hub-0.26.0-py3-none-any.whl (447 kB)\n",
            "Installing collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.30.2\n",
            "    Uninstalling huggingface-hub-0.30.2:\n",
            "      Successfully uninstalled huggingface-hub-0.30.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.51.0 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface_hub-0.26.0\n",
            "Requirement already satisfied: huggingface_hub in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (0.26.0)\n",
            "Collecting huggingface_hub\n",
            "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub) (4.67.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests->huggingface_hub) (2024.12.14)\n",
            "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "Installing collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.26.0\n",
            "    Uninstalling huggingface-hub-0.26.0:\n",
            "      Successfully uninstalled huggingface-hub-0.26.0\n",
            "Successfully installed huggingface_hub-0.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub==0.26.0\n",
        "!pip install --upgrade huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5ff88979",
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "hf_key = getpass(\"Hugging Face Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9f827ec2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `langchain` has been saved to /Users/ebengunadi/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /Users/ebengunadi/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `langchain`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login --token $hf_key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5f095bb",
      "metadata": {},
      "source": [
        "## Importing LangChain Libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1b24397a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f9b732b9",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b624f8fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ebbb77a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "#In a MAC Silicon the device must be 'mps'\n",
        "device = torch.device('mps') #to use with MAC Silicon\n",
        "# device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "49fa3289",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='mps')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30780dc3",
      "metadata": {},
      "source": [
        "##Load the Model ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1e0270e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "#You can try with any llama model, but you will need more GPU and memory as you\n",
        "#increase the size of the model.\n",
        "# model_id = \"meta-llama/Llama-3.2-1B-Instruct\" # Agreed per the 3/11/25 meeting, but not powerful enough!\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a61c23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install --upgrade transformers \n",
        "# !pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b93478d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from accelerate import init_empty_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0166401b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.19s/it]\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded on mps\n",
            "CPU times: user 3.29 s, sys: 3.13 s, total: 6.42 s\n",
            "Wall time: 10.9 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# begin initializing HF items, need auth token for these\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        "    token=hf_key\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    device_map='auto',\n",
        "    token=hf_key\n",
        ")\n",
        "model.eval()\n",
        "print(f\"Model loaded on {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "40d1d0eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id,\n",
        "                                          use_aut_token=hf_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3543a5e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use mps\n"
          ]
        }
      ],
      "source": [
        "# Set up the HuggingFace pipeline with your desired settings.\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=256, # ideally would be 1024, but takes too long given the resource constraints\n",
        "    temperature=0,         # Deterministic output\n",
        "    top_p=1.0,             # Allow full probability distribution\n",
        "    do_sample=False,       # Greedy decoding\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    repetition_penalty=1.0,  # Lowered if necessary\n",
        "    return_full_text=False,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "hf_llm = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "932be649",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define JSON schemas for conversion.\n",
        "basics_schema = '''{\n",
        "    \"name\": \"\",\n",
        "    \"label\": \"\",\n",
        "    \"image\": \"\",\n",
        "    \"email\": \"\",\n",
        "    \"phone\": \"\",\n",
        "    \"url\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"location\": {\n",
        "        \"address\": \"\",\n",
        "        \"postalCode\": \"\",\n",
        "        \"city\": \"\",\n",
        "        \"countryCode\": \"\",\n",
        "        \"region\": \"\"\n",
        "    },\n",
        "    \"profiles\": [\n",
        "        {\n",
        "            \"network\": \"\",\n",
        "            \"username\": \"\",\n",
        "            \"url\": \"\"\n",
        "        }\n",
        "    ]\n",
        "}'''\n",
        "\n",
        "work_schema = '''[\n",
        "    {\n",
        "        \"name\": \"\",\n",
        "        \"location\": \"\",\n",
        "        \"description\": \"\",\n",
        "        \"position\": \"\",\n",
        "        \"url\": \"\",\n",
        "        \"startDate\": \"\",\n",
        "        \"endDate\": \"\",\n",
        "        \"summary\": \"\",\n",
        "        \"highlights\": []\n",
        "    }\n",
        "]'''\n",
        "\n",
        "education_schema = '''[\n",
        "    {\n",
        "        \"institution\": \"\",\n",
        "        \"url\": \"\",\n",
        "        \"area\": \"\",\n",
        "        \"studyType\": \"\",\n",
        "        \"startDate\": \"\",\n",
        "        \"endDate\": \"\",\n",
        "        \"score\": \"\",\n",
        "        \"courses\": []\n",
        "    }\n",
        "]'''\n",
        "\n",
        "skills_schema = '''[\n",
        "    {\n",
        "        \"name\": \"\",\n",
        "        \"level\": \"\",\n",
        "        \"keywords\": []\n",
        "    }\n",
        "]'''\n",
        "\n",
        "projects_schema = '''[\n",
        "    {\n",
        "        \"name\": \"\",\n",
        "        \"description\": \"\",\n",
        "        \"highlights\": [],\n",
        "        \"keywords\": [],\n",
        "        \"startDate\": \"\",\n",
        "        \"endDate\": \"\",\n",
        "        \"url\": \"\",\n",
        "        \"roles\": [],\n",
        "        \"entity\": \"\",\n",
        "        \"type\": \"\"\n",
        "    }\n",
        "]'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "867a1805",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Optimized Conversion Prompts ---\n",
        "# These prompts convert the extracted raw text into the desired JSON format without any extra commentary.\n",
        "basics_conversion_prompt = (\n",
        "    \"Convert the extracted text into a JSON object that strictly adheres to the provided JSON schema. \"\n",
        "    \"Use only the information present in the text; for any field not mentioned, set its value to an empty string. \"\n",
        "    \"Output only the JSON object with no extra commentary or code.\\n\\n\"\n",
        "    \"Schema: {schema}\\n\\n\"\n",
        "    \"Extracted Text:\\n{text}\"\n",
        ")\n",
        "\n",
        "work_conversion_prompt = (\n",
        "    \"Convert the extracted text into a JSON array that strictly adheres to the provided JSON schema. \"\n",
        "    \"Use only the information present in the text; for any field not mentioned, set its value to an empty string. \"\n",
        "    \"Output only the JSON array with no extra commentary or code.\\n\"\n",
        "    \"### Schema:\\n{schema}\\n\"\n",
        "    \"### Extracted Text:\\n{text}\"\n",
        ")\n",
        "\n",
        "education_conversion_prompt = (\n",
        "    \"Convert the extracted text into a JSON array that strictly adheres to the provided JSON schema. \"\n",
        "    \"Use only the information present in the text; for any field not mentioned, set its value to an empty string. \"\n",
        "    \"Output only the JSON array with no extra commentary or code.\\n\\n\"\n",
        "    \"Schema: {schema}\\n\\n\"\n",
        "    \"Extracted Text:\\n{text}\"\n",
        ")\n",
        "\n",
        "skills_conversion_prompt = (\n",
        "    \"Convert the extracted text into a JSON array that strictly adheres to the provided JSON schema. \"\n",
        "    \"Use only the information present in the text; for any field not mentioned, set its value to an empty string. \"\n",
        "    \"Output only the JSON array with no extra commentary or code.\\n\\n\"\n",
        "    \"Schema: {schema}\\n\\n\"\n",
        "    \"Extracted Text:\\n{text}\"\n",
        ")\n",
        "\n",
        "projects_conversion_prompt = (\n",
        "    \"Convert the extracted text into a JSON array that strictly adheres to the provided JSON schema. \"\n",
        "    \"Use only the information present in the text; for any field not mentioned, set its value to an empty string. \"\n",
        "    \"Output only the JSON array with no extra commentary or code.\\n\\n\"\n",
        "    \"Schema: {schema}\\n\\n\"\n",
        "    \"Extracted Text:\\n{text}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "941c2b12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create conversion chains.\n",
        "basics_conversion_chain = (\n",
        "    {\"text\": RunnablePassthrough(), \"schema\": RunnablePassthrough()}\n",
        "    | ChatPromptTemplate.from_template(basics_conversion_prompt)\n",
        "    | hf_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "work_conversion_chain = (\n",
        "    {\"text\": RunnablePassthrough(), \"schema\": RunnablePassthrough()}\n",
        "    | ChatPromptTemplate.from_template(work_conversion_prompt)\n",
        "    | hf_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "education_conversion_chain = (\n",
        "    {\"text\": RunnablePassthrough(), \"schema\": RunnablePassthrough()}\n",
        "    | ChatPromptTemplate.from_template(education_conversion_prompt)\n",
        "    | hf_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "skills_conversion_chain = (\n",
        "    {\"text\": RunnablePassthrough(), \"schema\": RunnablePassthrough()}\n",
        "    | ChatPromptTemplate.from_template(skills_conversion_prompt)\n",
        "    | hf_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "projects_conversion_chain = (\n",
        "    {\"text\": RunnablePassthrough(), \"schema\": RunnablePassthrough()}\n",
        "    | ChatPromptTemplate.from_template(projects_conversion_prompt)\n",
        "    | hf_llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "e450ca97",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "\n",
            "JSON Object:\n",
            "{\n",
            "    \"name\": \"\",\n",
            "    \"label\": \"\",\n",
            "    \"image\": \"\",\n",
            "    \"email\": \"richard.hendriks@mail.com\",\n",
            "    \"phone\": \"\",\n",
            "    \"url\": \"http://richardhendricks.example.com\",\n",
            "    \"summary\": \"Richard hails from Tulsa. He has earned degrees from the University of Oklahoma and Stanford. (Go Sooners and\\nCardinal!) Before starting Pied Piper, he worked for Hooli as a part time software developer. While his work focuses on\\napplied information theory, mostly optimizing lossless compression schema of both the length-limited and adaptive\\nvariants, his non-work interests range widely, everything from quantum computing to chaos theory. He could tell you about\\nit, but THAT would NOT be a “length-limited” conversation!\",\n",
            "    \"location\": {\n",
            "        \"address\": \"\",\n",
            "        \"postalCode\": \"\",\n",
            "        \"city\": \"San Francisco, California\",\n",
            "        \"countryCode\": \"\",\n",
            "        \"region\": \"\"\n",
            "    },\n",
            "    \"profiles\": [\n",
            "        {\n",
            "            \"network\": \"\",\n",
            "            \"username\": \"\",\n",
            "            \"url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "} \n",
            "\n",
            "Note: The output JSON object is missing the'schema' key as it is not present in the extracted text\n",
            "CPU times: user 36 s, sys: 6min 3s, total: 6min 39s\n",
            "Wall time: 16min 22s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "basics_json_response = basics_conversion_chain.invoke({\"text\": basics_extracted, \"schema\": basics_schema})\n",
        "\n",
        "print(basics_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "562b8441",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_json_object(response: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts the JSON substring from the LLM response.\n",
        "    \"\"\"\n",
        "    match = re.search(r'(\\{.*\\})', response, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "5e540299",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': '',\n",
              " 'label': '',\n",
              " 'image': '',\n",
              " 'email': 'richard.hendriks@mail.com',\n",
              " 'phone': '',\n",
              " 'url': 'http://richardhendricks.example.com',\n",
              " 'summary': 'Richard hails from Tulsa. He has earned degrees from the University of Oklahoma and Stanford. (Go Sooners and\\nCardinal!) Before starting Pied Piper, he worked for Hooli as a part time software developer. While his work focuses on\\napplied information theory, mostly optimizing lossless compression schema of both the length-limited and adaptive\\nvariants, his non-work interests range widely, everything from quantum computing to chaos theory. He could tell you about\\nit, but THAT would NOT be a “length-limited” conversation!',\n",
              " 'location': {'address': '',\n",
              "  'postalCode': '',\n",
              "  'city': 'San Francisco, California',\n",
              "  'countryCode': '',\n",
              "  'region': ''},\n",
              " 'profiles': [{'network': '', 'username': '', 'url': ''}]}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basics_json_parsed = json.loads(extract_json_object(basics_json_response))\n",
        "basics_json_parsed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "2131727e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pied Piper CEO/President Dec 2013 — Dec 2014\n",
            "Build an algorithm for artist to detect if their music was violating copy right infringement laws\n",
            "Successfully won Techcrunch Disrupt\n",
            "Optimized an algorithm that holds the current world record for Weisman Scores\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(work_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "1e45a5fb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"name\": \"\",\n",
            "        \"location\": \"\",\n",
            "        \"description\": \"\",\n",
            "        \"position\": \"\",\n",
            "        \"url\": \"\",\n",
            "        \"startDate\": \"\",\n",
            "        \"endDate\": \"\",\n",
            "        \"summary\": \"\",\n",
            "        \"highlights\": []\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(work_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "62824e25",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n",
            "\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"name\": \"\",\n",
            "    \"location\": \"\",\n",
            "    \"description\": \"\",\n",
            "    \"position\": \"\",\n",
            "    \"url\": \"\",\n",
            "    \"startDate\": \"\",\n",
            "    \"endDate\": \"\",\n",
            "    \"summary\": \"\",\n",
            "    \"highlights\": []\n",
            "  }\n",
            "]\n",
            "``` \n",
            "\n",
            "Note: The provided schema and extracted text are identical, which means the output will be the same as the input. However, in a real-world scenario, you would need to parse the extracted text and create a new JSON array based on the schema.\n",
            "CPU times: user 13.6 s, sys: 2min 14s, total: 2min 27s\n",
            "Wall time: 6min 29s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "work_json_response = work_conversion_chain.invoke({\"text\": work_extracted, \"schema\": work_schema})\n",
        "\n",
        "print(work_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "69c987b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_first_json_array(response: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts the JSON array substring from the LLM response.\n",
        "    Due to the 256 max token limit, just return the first object in the array and add a closing bracket.\n",
        "    \"\"\"\n",
        "    match = re.search(r'(\\[.*?\\})', response, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1) + ']'\n",
        "    return response\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "d6f214ca",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'Information Technology Supervisor',\n",
              "  'location': 'City, State',\n",
              "  'description': '',\n",
              "  'position': 'Supervise up to 10 personnel at one time, delegating tasks, conducting performance evaluations and providing corrective counseling as necessary. Train personnel in the set-up and proper use of IT related equipment while adhering to all policies and procedures. Responsible for the inventory of over $1 million worth of network communications equipment. Tasked by President of the United States to act as supervisor and maintain signal communications for Fort Bragg army base.',\n",
              "  'url': '',\n",
              "  'startDate': '01/2011',\n",
              "  'endDate': '05/2014',\n",
              "  'summary': '',\n",
              "  'highlights': []}]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "work_json_parsed = json.loads(extract_first_json_array(work_json_response))\n",
        "work_json_parsed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "44b4c832",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Do not include the course numbers.\n",
            "\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"institution\": \"Microsoft\",\n",
            "    \"url\": \"\",\n",
            "    \"area\": \"\",\n",
            "    \"studyType\": \"\",\n",
            "    \"startDate\": \"\",\n",
            "    \"endDate\": \"\",\n",
            "    \"score\": \"\",\n",
            "    \"courses\": [\n",
            "      \"Information Technology (Network Communications)\",\n",
            "      \"IT Network and Cisco Routing\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"institution\": \"Comptia\",\n",
            "    \"url\": \"\",\n",
            "    \"area\": \"\",\n",
            "    \"studyType\": \"\",\n",
            "    \"startDate\": \"\",\n",
            "    \"endDate\": \"\",\n",
            "    \"score\": \"\",\n",
            "    \"courses\": [\n",
            "      \"Security\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"institution\": \"U.S. Army\",\n",
            "    \"url\": \"\",\n",
            "    \"area\": \"\",\n",
            "    \"studyType\": \"\",\n",
            "    \"startDate\": \"\",\n",
            "    \"endDate\": \"\",\n",
            "    \"score\": \"\",\n",
            "    \"courses\": [\n",
            "      \"Information Technology (Network Communications)\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"institution\": \"Northwest Florida State College\",\n",
            "    \"url\": \"\",\n",
            "    \"area\": \"\",\n",
            "    \"studyType\": \"\",\n",
            "    \"startDate\": \"\",\n",
            "    \"endDate\": \"\",\n",
            "    \"score\": \"\",\n",
            "    \"courses\": [\n",
            "      \"Radiography\"\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"institution\": \"\n",
            "CPU times: user 18.2 s, sys: 46.8 s, total: 1min 4s\n",
            "Wall time: 2min 19s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# if the extracted text startsWith \"No.*section found\" is in the extracted text, just return the schema\n",
        "# else run the conversion chain\n",
        "\n",
        "if re.match(r\"^No\\s+\\w+\\s+section\\s+found\\.?\", education_extracted.strip(), re.IGNORECASE) is not None:\n",
        "    education_json_response = education_schema\n",
        "else:\n",
        "    education_json_response = education_conversion_chain.invoke({\"text\": education_extracted, \"schema\": education_schema})\n",
        "\n",
        "print(education_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "c484d704",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'institution': 'Microsoft',\n",
              "  'url': '',\n",
              "  'area': '',\n",
              "  'studyType': '',\n",
              "  'startDate': '',\n",
              "  'endDate': '',\n",
              "  'score': '',\n",
              "  'courses': ['Information Technology (Network Communications)',\n",
              "   'IT Network and Cisco Routing']}]"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "education_json_parsed = json.loads(extract_first_json_array(education_json_response))\n",
        "education_json_parsed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "e38a51f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"name\": \"\",\n",
            "        \"level\": \"\",\n",
            "        \"keywords\": []\n",
            "    }\n",
            "]\n",
            "CPU times: user 91 µs, sys: 122 µs, total: 213 µs\n",
            "Wall time: 428 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# if the extracted text startsWith \"No.*section found\" is in the extracted text, just return the schema\n",
        "# else run the conversion chain\n",
        "\n",
        "if re.match(r\"^No\\s+\\w+\\s+section\\s+found\\.?\", skills_extracted.strip(), re.IGNORECASE) is not None:\n",
        "    skills_json_response = skills_schema\n",
        "else:\n",
        "    skills_json_response = skills_conversion_chain.invoke({\"text\": skills_extracted, \"schema\": skills_schema})\n",
        "\n",
        "print(skills_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "b33b7d7c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': '', 'level': '', 'keywords': []}]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skills_json_parsed = json.loads(extract_first_json_array(skills_json_response))\n",
        "skills_json_parsed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "5c9a25e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"name\": \"\",\n",
            "        \"description\": \"\",\n",
            "        \"highlights\": [],\n",
            "        \"keywords\": [],\n",
            "        \"startDate\": \"\",\n",
            "        \"endDate\": \"\",\n",
            "        \"url\": \"\",\n",
            "        \"roles\": [],\n",
            "        \"entity\": \"\",\n",
            "        \"type\": \"\"\n",
            "    }\n",
            "]\n",
            "CPU times: user 269 µs, sys: 187 µs, total: 456 µs\n",
            "Wall time: 634 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# if the extracted text startsWith \"No.*section found\" is in the extracted text, just return the schema\n",
        "# else run the conversion chain\n",
        "\n",
        "if re.match(r\"^No\\s+\\w+\\s+section\\s+found\\.?\", projects_extracted.strip(), re.IGNORECASE) is not None:\n",
        "    projects_json_response = projects_schema\n",
        "else:\n",
        "    projects_json_response = projects_conversion_chain.invoke({\"text\": projects_extracted, \"schema\": projects_schema})\n",
        "\n",
        "print(projects_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "24cecff2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': '',\n",
              "  'description': '',\n",
              "  'highlights': [],\n",
              "  'keywords': [],\n",
              "  'startDate': '',\n",
              "  'endDate': '',\n",
              "  'url': '',\n",
              "  'roles': [],\n",
              "  'entity': '',\n",
              "  'type': ''}]"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "projects_json_parsed = json.loads(extract_first_json_array(projects_json_response))\n",
        "projects_json_parsed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b6fe7e0",
      "metadata": {},
      "source": [
        "## Put together the final JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "32c6e8c6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'$schema': 'https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/schema.json',\n",
              " 'basics': {'name': '',\n",
              "  'label': '',\n",
              "  'image': '',\n",
              "  'email': '',\n",
              "  'phone': '',\n",
              "  'url': '',\n",
              "  'summary': '',\n",
              "  'location': {'address': '',\n",
              "   'postalCode': '',\n",
              "   'city': '',\n",
              "   'countryCode': '',\n",
              "   'region': ''},\n",
              "  'profiles': [{'network': '', 'username': '', 'url': ''}]},\n",
              " 'work': [{'name': 'Information Technology Supervisor',\n",
              "   'location': 'City, State',\n",
              "   'description': '',\n",
              "   'position': 'Supervise up to 10 personnel at one time, delegating tasks, conducting performance evaluations and providing corrective counseling as necessary. Train personnel in the set-up and proper use of IT related equipment while adhering to all policies and procedures. Responsible for the inventory of over $1 million worth of network communications equipment. Tasked by President of the United States to act as supervisor and maintain signal communications for Fort Bragg army base.',\n",
              "   'url': '',\n",
              "   'startDate': '01/2011',\n",
              "   'endDate': '05/2014',\n",
              "   'summary': '',\n",
              "   'highlights': []}],\n",
              " 'education': [{'institution': 'Microsoft',\n",
              "   'url': '',\n",
              "   'area': '',\n",
              "   'studyType': '',\n",
              "   'startDate': '',\n",
              "   'endDate': '',\n",
              "   'score': '',\n",
              "   'courses': ['Information Technology (Network Communications)',\n",
              "    'IT Network and Cisco Routing']}],\n",
              " 'skills': [{'name': '', 'level': '', 'keywords': []}],\n",
              " 'projects': [{'name': '',\n",
              "   'description': '',\n",
              "   'highlights': [],\n",
              "   'keywords': [],\n",
              "   'startDate': '',\n",
              "   'endDate': '',\n",
              "   'url': '',\n",
              "   'roles': [],\n",
              "   'entity': '',\n",
              "   'type': ''}],\n",
              " 'meta': {'canonical': 'https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/sample.resume.json',\n",
              "  'version': 'v1.0.0',\n",
              "  'lastModified': '2017-12-24T15:53:00'}}"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# put it all together\n",
        "\n",
        "resume_json = {\n",
        "    \"$schema\": \"https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/schema.json\",\n",
        "    \"basics\": basics_json_parsed,\n",
        "    \"work\": work_json_parsed,\n",
        "    \"education\": education_json_parsed,\n",
        "    \"skills\": skills_json_parsed,\n",
        "    \"projects\": projects_json_parsed,\n",
        "    \"meta\": {\n",
        "        \"canonical\": \"https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/sample.resume.json\",\n",
        "        \"version\": \"v1.0.0\",\n",
        "        \"lastModified\": \"2017-12-24T15:53:00\"\n",
        "    }\n",
        "}\n",
        "\n",
        "resume_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "5b3287bf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resume JSON saved to ../data/INFORMATION-TECHNOLOGY-JSON/33241454.json\n"
          ]
        }
      ],
      "source": [
        "output_file = '../data/INFORMATION-TECHNOLOGY-JSON/33241454.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(resume_json, f, indent=4)\n",
        "    print(f\"Resume JSON saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af96a34b",
      "metadata": {},
      "source": [
        "## Cleanup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a100825",
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install \"huggingface_hub[cli]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd4a60b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# cleanup huggingface LLMs\n",
        "\n",
        "# run this command in the terminal\n",
        "# huggingface-cli delete-cache"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "grids-resume",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 301.368093,
      "end_time": "2023-11-07T23:43:39.05917",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-11-07T23:38:37.691077",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
