{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f407d757",
      "metadata": {
        "id": "f407d757",
        "papermill": {
          "duration": 0.022555,
          "end_time": "2023-11-07T23:40:10.609309",
          "exception": false,
          "start_time": "2023-11-07T23:40:10.586754",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "09ea9d7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:10.558175Z",
          "iopub.status.busy": "2023-11-07T23:40:10.55769Z",
          "iopub.status.idle": "2023-11-07T23:40:10.562952Z",
          "shell.execute_reply": "2023-11-07T23:40:10.561864Z"
        },
        "id": "09ea9d7c",
        "papermill": {
          "duration": 0.030688,
          "end_time": "2023-11-07T23:40:10.565135",
          "exception": false,
          "start_time": "2023-11-07T23:40:10.534447",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "import glob\n",
        "import json\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a39dfc3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/19/25, 10:19 PM Richard Hendriks\n",
            "richard.hendriks@mail.com\n",
            "Richard Hendriks\n",
            "http://richardhendricks.example.com\n",
            "San Francisco, California\n",
            "SUMMARY\n",
            "Richard hails from Tulsa. He has earned degrees from the University of Oklahoma and Stanford. (Go Sooners and\n",
            "Cardinal!) Before starting Pied Piper, he worked for Hooli as a part time software developer. While his work focuses on\n",
            "applied information theory, mostly optimizing lossless compression schema of both the length-limited and adaptive\n",
            "variants, his non-work interests range widely, everything from quantum computing to chaos theory. He could tell you about\n",
            "it, but THAT would NOT be a “length-limited” conversation!\n",
            "SKILLS AND TECH\n",
            "Web Development: HTML, CSS, Javascript.\n",
            "Compression: Mpeg, MP4, GIF.\n",
            "EXPERIENCE\n",
            "Pied Piper CEO/President Dec 2013 — Dec 2014\n",
            "Build an algorithm for artist to detect if their music was violating copy right infringement laws\n",
            "Successfully won Techcrunch Disrupt\n",
            "Optimized an algorithm that holds the current world record for Weisman Scores\n",
            "VOLUNTEERING\n",
            "CoderDojo Teacher Jan 2012 — Jan 2013\n",
            "Awarded 'Teacher of the Month'\n",
            "PROJECTS\n",
            "Miss Direction: Won award at AIHacks 2016. Built by all women team of newbie programmers. Using modern\n",
            "technologies such as GoogleMaps, Chrome Extension and Javascript.\n",
            "EDUCATION\n",
            "University of Oklahoma Jun 2011 — Jan 2014\n",
            "Bachelor - Information Technology, GPA: 4.0\n",
            "PUBLICATIONS\n",
            "Video compression for 3d media Oct 2014\n",
            "AWARDS\n",
            "Digital Compression Pioneer Award, Techcrunch Nov 2014\n",
            "INTERESTS\n",
            "Wildlife: Ferrets, Unicorns\n",
            "https://slugstack.github.io/jsonresume-theme-straightforward/ 1/1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pdf_path = '../data/Richard Hendriks.pdf' # as agreed in whatsapp\n",
        "\n",
        "pdf_text = ''\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            pdf_text += page_text + '\\n'\n",
        "\n",
        "print(pdf_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e9cdec9",
      "metadata": {},
      "source": [
        "# Use regex to break the text into sections\n",
        "## LLM can be used but would be too slow for the demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b26a27a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/19/25, 10:19 PM Richard Hendriks\n",
            "richard.hendriks@mail.com\n",
            "Richard Hendriks\n",
            "http://richardhendricks.example.com\n",
            "San Francisco, California\n",
            "SUMMARY\n",
            "Richard hails from Tulsa. He has earned degrees from the University of Oklahoma and Stanford. (Go Sooners and\n",
            "Cardinal!) Before starting Pied Piper, he worked for Hooli as a part time software developer. While his work focuses on\n",
            "applied information theory, mostly optimizing lossless compression schema of both the length-limited and adaptive\n",
            "variants, his non-work interests range widely, everything from quantum computing to chaos theory. He could tell you about\n",
            "it, but THAT would NOT be a “length-limited” conversation!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'SUMMARY' section from the resume text by grabbing everything from the beginning up to 'SKILLS AND TECH'\n",
        "basics_extracted = pdf_text.split('SKILLS AND TECH')[0]\n",
        "print(basics_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fce11ff6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Web Development: HTML, CSS, Javascript.\n",
            "Compression: Mpeg, MP4, GIF.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'SKILLS AND TECH' section from the resume text by grabbing everything from 'SKILLS AND TECH' to 'EXPERIENCE'\n",
        "skills_extracted = pdf_text.split('EXPERIENCE')[0].split('SKILLS AND TECH')[1]\n",
        "print(skills_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7316336c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pied Piper CEO/President Dec 2013 — Dec 2014\n",
            "Build an algorithm for artist to detect if their music was violating copy right infringement laws\n",
            "Successfully won Techcrunch Disrupt\n",
            "Optimized an algorithm that holds the current world record for Weisman Scores\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'EXPERIENCE' section from the resume text by grabbing everything from 'EXPERIENCE' to 'VOLUNTEERING'\n",
        "work_extracted = pdf_text.split('VOLUNTEERING')[0].split('EXPERIENCE')[1]\n",
        "print(work_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4a84e456",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Miss Direction: Won award at AIHacks 2016. Built by all women team of newbie programmers. Using modern\n",
            "technologies such as GoogleMaps, Chrome Extension and Javascript.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'PROJECTS' section from the resume text by grabbing everything from 'PROJECTS' to 'EDUCATION'\n",
        "projects_extracted = pdf_text.split('EDUCATION')[0].split('PROJECTS')[1]\n",
        "print(projects_extracted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "22234406",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "University of Oklahoma Jun 2011 — Jan 2014\n",
            "Bachelor - Information Technology, GPA: 4.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Extract the 'EDUCATION' section from the resume text by grabbing everything from 'EDUCATION' to 'PUBLICATIONS'\n",
        "education_extracted = pdf_text.split('PUBLICATIONS')[0].split('EDUCATION')[1]\n",
        "print(education_extracted)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a510e9ce",
      "metadata": {},
      "source": [
        "# Load the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d0d19437",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (0.2.17)\n",
            "Collecting langchain\n",
            "  Using cached langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: langchain-openai in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (0.1.25)\n",
            "Collecting langchain-openai\n",
            "  Using cached langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: openai in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (1.75.0)\n",
            "Requirement already satisfied: pydantic==1.10.13 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (1.10.13)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from pydantic==1.10.13) (4.12.2)\n",
            "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
            "  Using cached langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (0.1.147)\n",
            "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain\n",
            "  Using cached langchain-0.3.22-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Using cached langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Using cached langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "  Using cached langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Using cached langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Using cached langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (1.26.4)\n",
            "  Using cached langchain-0.3.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain-0.3.15-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.6-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.5-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.43 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (0.2.43)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (0.2.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain) (8.5.0)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai\n",
            "  Using cached langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "  Using cached langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Using cached langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "  Using cached langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from openai) (4.67.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.43->langchain) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade \\\n",
        "  langchain \\\n",
        "  langchain-openai \\\n",
        "  openai \\\n",
        "  pydantic==1.10.13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d5705cb3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5ff88979",
      "metadata": {},
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "openai_key = getpass(\"OpenAI Key: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "373e1a8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dba7a4fa",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/h1/r_7yspw94w77hrsrcwzwy75m0000gn/T/ipykernel_20109/1655464026.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n"
          ]
        }
      ],
      "source": [
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o\") "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "708820c5",
      "metadata": {
        "id": "708820c5",
        "papermill": {
          "duration": 0.034723,
          "end_time": "2023-11-07T23:40:40.687547",
          "exception": false,
          "start_time": "2023-11-07T23:40:40.652824",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## LANGCHAIN\n",
        "\n",
        "### Using the new LCEL Architecture from LangChain.\n",
        "LangChain recommends using LCEL (LangChain Expression Language) over Chains. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5f095bb",
      "metadata": {},
      "source": [
        "## Importing LangChain Libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1b24397a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "932be649",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define JSON schemas for conversion.\n",
        "basics_schema = '''{\n",
        "    \"name\": \"\",\n",
        "    \"label\": \"\",\n",
        "    \"image\": \"\",\n",
        "    \"email\": \"\",\n",
        "    \"phone\": \"\",\n",
        "    \"url\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"location\": {\n",
        "        \"address\": \"\",\n",
        "        \"postalCode\": \"\",\n",
        "        \"city\": \"\",\n",
        "        \"countryCode\": \"\",\n",
        "        \"region\": \"\"\n",
        "    },\n",
        "    \"profiles\": [\n",
        "        {\n",
        "            \"network\": \"\",\n",
        "            \"username\": \"\",\n",
        "            \"url\": \"\"\n",
        "        }\n",
        "    ]\n",
        "}'''\n",
        "\n",
        "work_schema = '''[\n",
        "    {\n",
        "        \"name\": \"\",\n",
        "        \"location\": \"\",\n",
        "        \"description\": \"\",\n",
        "        \"position\": \"\",\n",
        "        \"url\": \"\",\n",
        "        \"startDate\": \"\",\n",
        "        \"endDate\": \"\",\n",
        "        \"summary\": \"\",\n",
        "        \"highlights\": []\n",
        "    }\n",
        "]'''\n",
        "\n",
        "education_schema = '''[\n",
        "    {\n",
        "        \"institution\": \"\",\n",
        "        \"url\": \"\",\n",
        "        \"area\": \"\",\n",
        "        \"studyType\": \"\",\n",
        "        \"startDate\": \"\",\n",
        "        \"endDate\": \"\",\n",
        "        \"score\": \"\",\n",
        "        \"courses\": []\n",
        "    }\n",
        "]'''\n",
        "\n",
        "skills_schema = '''[\n",
        "    {\n",
        "        \"name\": \"\",\n",
        "        \"level\": \"\",\n",
        "        \"keywords\": []\n",
        "    }\n",
        "]'''\n",
        "\n",
        "projects_schema = '''[\n",
        "    {\n",
        "        \"name\": \"\",\n",
        "        \"description\": \"\",\n",
        "        \"highlights\": [],\n",
        "        \"keywords\": [],\n",
        "        \"startDate\": \"\",\n",
        "        \"endDate\": \"\",\n",
        "        \"url\": \"\",\n",
        "        \"roles\": [],\n",
        "        \"entity\": \"\",\n",
        "        \"type\": \"\"\n",
        "    }\n",
        "]'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "683455ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "conversion_prompt = (\n",
        "    \"Convert the extracted text into a JSON object or array that strictly adheres to the provided JSON schema. \"\n",
        "    \"Use only the information present in the text; for any field not mentioned, set its value to an empty string. \"\n",
        "    \"Output only the JSON array with no extra commentary or code.\\n\"\n",
        "    \"### Schema:\\n{schema}\\n\"\n",
        "    \"### Extracted Text:\\n{text}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dd8d8a0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "conversion_chain = (\n",
        "    {\"text\": RunnablePassthrough(), \"schema\": RunnablePassthrough()}\n",
        "    | ChatPromptTemplate.from_template(conversion_prompt)\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "956f120e",
      "metadata": {},
      "source": [
        "### \"Basics\" Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "46c8708e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "    \"name\": \"Richard Hendriks\",\n",
            "    \"label\": \"\",\n",
            "    \"image\": \"\",\n",
            "    \"email\": \"richard.hendriks@mail.com\",\n",
            "    \"phone\": \"\",\n",
            "    \"url\": \"http://richardhendricks.example.com\",\n",
            "    \"summary\": \"Richard hails from Tulsa. He has earned degrees from the University of Oklahoma and Stanford. (Go Sooners and Cardinal!) Before starting Pied Piper, he worked for Hooli as a part time software developer. While his work focuses on applied information theory, mostly optimizing lossless compression schema of both the length-limited and adaptive variants, his non-work interests range widely, everything from quantum computing to chaos theory. He could tell you about it, but THAT would NOT be a “length-limited” conversation!\",\n",
            "    \"location\": {\n",
            "        \"address\": \"\",\n",
            "        \"postalCode\": \"\",\n",
            "        \"city\": \"San Francisco\",\n",
            "        \"countryCode\": \"\",\n",
            "        \"region\": \"California\"\n",
            "    },\n",
            "    \"profiles\": [\n",
            "        {\n",
            "            \"network\": \"\",\n",
            "            \"username\": \"\",\n",
            "            \"url\": \"\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "```\n",
            "CPU times: user 18.7 ms, sys: 6.29 ms, total: 25 ms\n",
            "Wall time: 3.81 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "basics_json_response = conversion_chain.invoke({\"text\": basics_extracted, \"schema\": basics_schema})\n",
        "\n",
        "print(basics_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "eacb4686",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_json_object(response: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts the JSON substring from the LLM response.\n",
        "    \"\"\"\n",
        "    match = re.search(r'(\\{.*\\})', response, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "dc24171c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'Richard Hendriks',\n",
              " 'label': '',\n",
              " 'image': '',\n",
              " 'email': 'richard.hendriks@mail.com',\n",
              " 'phone': '',\n",
              " 'url': 'http://richardhendricks.example.com',\n",
              " 'summary': 'Richard hails from Tulsa. He has earned degrees from the University of Oklahoma and Stanford. (Go Sooners and Cardinal!) Before starting Pied Piper, he worked for Hooli as a part time software developer. While his work focuses on applied information theory, mostly optimizing lossless compression schema of both the length-limited and adaptive variants, his non-work interests range widely, everything from quantum computing to chaos theory. He could tell you about it, but THAT would NOT be a “length-limited” conversation!',\n",
              " 'location': {'address': '',\n",
              "  'postalCode': '',\n",
              "  'city': 'San Francisco',\n",
              "  'countryCode': '',\n",
              "  'region': 'California'},\n",
              " 'profiles': [{'network': '', 'username': '', 'url': ''}]}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basics_json_parsed = json.loads(extract_json_object(basics_json_response))\n",
        "basics_json_parsed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f32e6517",
      "metadata": {},
      "source": [
        "### \"Work\" Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "62824e25",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "[\n",
            "    {\n",
            "        \"name\": \"Pied Piper\",\n",
            "        \"location\": \"\",\n",
            "        \"description\": \"\",\n",
            "        \"position\": \"CEO/President\",\n",
            "        \"url\": \"\",\n",
            "        \"startDate\": \"Dec 2013\",\n",
            "        \"endDate\": \"Dec 2014\",\n",
            "        \"summary\": \"\",\n",
            "        \"highlights\": [\n",
            "            \"Build an algorithm for artist to detect if their music was violating copy right infringement laws\",\n",
            "            \"Successfully won Techcrunch Disrupt\",\n",
            "            \"Optimized an algorithm that holds the current world record for Weisman Scores\"\n",
            "        ]\n",
            "    }\n",
            "]\n",
            "```\n",
            "CPU times: user 15.7 ms, sys: 3.44 ms, total: 19.2 ms\n",
            "Wall time: 1.92 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "work_json_response = conversion_chain.invoke({\"text\": work_extracted, \"schema\": work_schema})\n",
        "\n",
        "print(work_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5397aa24",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_json_array(response: str) -> str:\n",
        "    \"\"\"\n",
        "    Extracts the JSON array substring from the LLM response.\n",
        "    \"\"\"\n",
        "    match = re.search(r'(\\[.*\\])', response, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d6f214ca",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'Pied Piper',\n",
              "  'location': '',\n",
              "  'description': '',\n",
              "  'position': 'CEO/President',\n",
              "  'url': '',\n",
              "  'startDate': 'Dec 2013',\n",
              "  'endDate': 'Dec 2014',\n",
              "  'summary': '',\n",
              "  'highlights': ['Build an algorithm for artist to detect if their music was violating copy right infringement laws',\n",
              "   'Successfully won Techcrunch Disrupt',\n",
              "   'Optimized an algorithm that holds the current world record for Weisman Scores']}]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "work_json_parsed = json.loads(extract_json_array(work_json_response))\n",
        "work_json_parsed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dd9856f",
      "metadata": {},
      "source": [
        "### \"Education\" Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "44b4c832",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "[\n",
            "    {\n",
            "        \"institution\": \"University of Oklahoma\",\n",
            "        \"url\": \"\",\n",
            "        \"area\": \"Information Technology\",\n",
            "        \"studyType\": \"Bachelor\",\n",
            "        \"startDate\": \"Jun 2011\",\n",
            "        \"endDate\": \"Jan 2014\",\n",
            "        \"score\": \"4.0\",\n",
            "        \"courses\": []\n",
            "    }\n",
            "]\n",
            "```\n",
            "CPU times: user 10.5 ms, sys: 3.02 ms, total: 13.5 ms\n",
            "Wall time: 937 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "education_json_response = conversion_chain.invoke({\"text\": education_extracted, \"schema\": education_schema})\n",
        "\n",
        "print(education_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "c484d704",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'institution': 'University of Oklahoma',\n",
              "  'url': '',\n",
              "  'area': 'Information Technology',\n",
              "  'studyType': 'Bachelor',\n",
              "  'startDate': 'Jun 2011',\n",
              "  'endDate': 'Jan 2014',\n",
              "  'score': '4.0',\n",
              "  'courses': []}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "education_json_parsed = json.loads(extract_json_array(education_json_response))\n",
        "education_json_parsed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cff4b909",
      "metadata": {},
      "source": [
        "### \"Skills\" Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e38a51f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "[\n",
            "    {\n",
            "        \"name\": \"Web Development\",\n",
            "        \"level\": \"\",\n",
            "        \"keywords\": [\"HTML\", \"CSS\", \"Javascript\"]\n",
            "    },\n",
            "    {\n",
            "        \"name\": \"Compression\",\n",
            "        \"level\": \"\",\n",
            "        \"keywords\": [\"Mpeg\", \"MP4\", \"GIF\"]\n",
            "    }\n",
            "]\n",
            "```\n",
            "CPU times: user 15.1 ms, sys: 3.51 ms, total: 18.6 ms\n",
            "Wall time: 1.22 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "skills_json_response = conversion_chain.invoke({\"text\": skills_extracted, \"schema\": skills_schema})\n",
        "\n",
        "print(skills_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b33b7d7c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'Web Development',\n",
              "  'level': '',\n",
              "  'keywords': ['HTML', 'CSS', 'Javascript']},\n",
              " {'name': 'Compression', 'level': '', 'keywords': ['Mpeg', 'MP4', 'GIF']}]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skills_json_parsed = json.loads(extract_json_array(skills_json_response))\n",
        "skills_json_parsed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8373b54",
      "metadata": {},
      "source": [
        "### \"Projects\" Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5c9a25e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "[\n",
            "    {\n",
            "        \"name\": \"Miss Direction\",\n",
            "        \"description\": \"\",\n",
            "        \"highlights\": [\n",
            "            \"Won award at AIHacks 2016\",\n",
            "            \"Built by all women team of newbie programmers\"\n",
            "        ],\n",
            "        \"keywords\": [\n",
            "            \"GoogleMaps\",\n",
            "            \"Chrome Extension\",\n",
            "            \"Javascript\"\n",
            "        ],\n",
            "        \"startDate\": \"\",\n",
            "        \"endDate\": \"\",\n",
            "        \"url\": \"\",\n",
            "        \"roles\": [],\n",
            "        \"entity\": \"\",\n",
            "        \"type\": \"\"\n",
            "    }\n",
            "]\n",
            "```\n",
            "CPU times: user 13.7 ms, sys: 2.79 ms, total: 16.5 ms\n",
            "Wall time: 1.35 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "projects_json_response = conversion_chain.invoke({\"text\": projects_extracted, \"schema\": projects_schema})\n",
        "\n",
        "print(projects_json_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "24cecff2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'Miss Direction',\n",
              "  'description': '',\n",
              "  'highlights': ['Won award at AIHacks 2016',\n",
              "   'Built by all women team of newbie programmers'],\n",
              "  'keywords': ['GoogleMaps', 'Chrome Extension', 'Javascript'],\n",
              "  'startDate': '',\n",
              "  'endDate': '',\n",
              "  'url': '',\n",
              "  'roles': [],\n",
              "  'entity': '',\n",
              "  'type': ''}]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "projects_json_parsed = json.loads(extract_json_array(projects_json_response))\n",
        "projects_json_parsed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b6fe7e0",
      "metadata": {},
      "source": [
        "## Put together the final JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "32c6e8c6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'$schema': 'https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/schema.json',\n",
              " 'basics': {'name': 'Richard Hendriks',\n",
              "  'label': '',\n",
              "  'image': '',\n",
              "  'email': 'richard.hendriks@mail.com',\n",
              "  'phone': '',\n",
              "  'url': 'http://richardhendricks.example.com',\n",
              "  'summary': 'Richard hails from Tulsa. He has earned degrees from the University of Oklahoma and Stanford. (Go Sooners and Cardinal!) Before starting Pied Piper, he worked for Hooli as a part time software developer. While his work focuses on applied information theory, mostly optimizing lossless compression schema of both the length-limited and adaptive variants, his non-work interests range widely, everything from quantum computing to chaos theory. He could tell you about it, but THAT would NOT be a “length-limited” conversation!',\n",
              "  'location': {'address': '',\n",
              "   'postalCode': '',\n",
              "   'city': 'San Francisco',\n",
              "   'countryCode': '',\n",
              "   'region': 'California'},\n",
              "  'profiles': [{'network': '', 'username': '', 'url': ''}]},\n",
              " 'work': [{'name': 'Pied Piper',\n",
              "   'location': '',\n",
              "   'description': '',\n",
              "   'position': 'CEO/President',\n",
              "   'url': '',\n",
              "   'startDate': 'Dec 2013',\n",
              "   'endDate': 'Dec 2014',\n",
              "   'summary': '',\n",
              "   'highlights': ['Build an algorithm for artist to detect if their music was violating copy right infringement laws',\n",
              "    'Successfully won Techcrunch Disrupt',\n",
              "    'Optimized an algorithm that holds the current world record for Weisman Scores']}],\n",
              " 'education': [{'institution': 'University of Oklahoma',\n",
              "   'url': '',\n",
              "   'area': 'Information Technology',\n",
              "   'studyType': 'Bachelor',\n",
              "   'startDate': 'Jun 2011',\n",
              "   'endDate': 'Jan 2014',\n",
              "   'score': '4.0',\n",
              "   'courses': []}],\n",
              " 'skills': [{'name': 'Web Development',\n",
              "   'level': '',\n",
              "   'keywords': ['HTML', 'CSS', 'Javascript']},\n",
              "  {'name': 'Compression', 'level': '', 'keywords': ['Mpeg', 'MP4', 'GIF']}],\n",
              " 'projects': [{'name': 'Miss Direction',\n",
              "   'description': '',\n",
              "   'highlights': ['Won award at AIHacks 2016',\n",
              "    'Built by all women team of newbie programmers'],\n",
              "   'keywords': ['GoogleMaps', 'Chrome Extension', 'Javascript'],\n",
              "   'startDate': '',\n",
              "   'endDate': '',\n",
              "   'url': '',\n",
              "   'roles': [],\n",
              "   'entity': '',\n",
              "   'type': ''}],\n",
              " 'meta': {'canonical': 'https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/sample.resume.json',\n",
              "  'version': 'v1.0.0',\n",
              "  'lastModified': '2017-12-24T15:53:00'}}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# put it all together\n",
        "\n",
        "resume_json = {\n",
        "    \"$schema\": \"https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/schema.json\",\n",
        "    \"basics\": basics_json_parsed,\n",
        "    \"work\": work_json_parsed,\n",
        "    \"education\": education_json_parsed,\n",
        "    \"skills\": skills_json_parsed,\n",
        "    \"projects\": projects_json_parsed,\n",
        "    \"meta\": {\n",
        "        \"canonical\": \"https://raw.githubusercontent.com/jsonresume/resume-schema/v1.0.0/sample.resume.json\",\n",
        "        \"version\": \"v1.0.0\",\n",
        "        \"lastModified\": \"2017-12-24T15:53:00\"\n",
        "    }\n",
        "}\n",
        "\n",
        "resume_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "5b3287bf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resume JSON saved to ../data/Richard Hendricks.json\n"
          ]
        }
      ],
      "source": [
        "output_file = '../data/Richard Hendricks.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(resume_json, f, indent=4)\n",
        "    print(f\"Resume JSON saved to {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "grids-resume",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 301.368093,
      "end_time": "2023-11-07T23:43:39.05917",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-11-07T23:38:37.691077",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
