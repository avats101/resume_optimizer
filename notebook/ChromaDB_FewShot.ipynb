{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5bac2f0d",
      "metadata": {
        "id": "5bac2f0d",
        "papermill": {
          "duration": 0.010703,
          "end_time": "2023-11-07T23:38:48.894198",
          "exception": false,
          "start_time": "2023-11-07T23:38:48.883495",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Install and load the libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1ecaf9c5",
      "metadata": {
        "_kg_hide-output": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-07T23:38:48.918551Z",
          "iopub.status.busy": "2023-11-07T23:38:48.917508Z",
          "iopub.status.idle": "2023-11-07T23:40:10.466442Z",
          "shell.execute_reply": "2023-11-07T23:40:10.465295Z"
        },
        "id": "1ecaf9c5",
        "outputId": "502a6e6e-4523-4d89-9e73-46c37693417c",
        "papermill": {
          "duration": 81.563917,
          "end_time": "2023-11-07T23:40:10.469187",
          "exception": false,
          "start_time": "2023-11-07T23:38:48.90527",
          "status": "completed"
        },
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# !pip install -q chromadb==0.4.22\n",
        "# !pip install -q langchain==0.1.4\n",
        "# !pip install -q sentence_transformers==2.3.0\n",
        "# !pip install -q accelerate==0.26.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f407d757",
      "metadata": {
        "id": "f407d757",
        "papermill": {
          "duration": 0.022555,
          "end_time": "2023-11-07T23:40:10.609309",
          "exception": false,
          "start_time": "2023-11-07T23:40:10.586754",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "01e2cb82",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('../data')\n",
        "\n",
        "from resume_templates import RESUME_TEMPLATES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9a44bf0a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'input': '\\n\"work\": [\\n  {\\n    \"highlights\": [\\n      \"Painted murals for a few local cafes — they gave me free reign on design\",\\n      \"Also made digital illustrations for some small online businesses\",\\n      \"One client asked for revisions last-minute and I had to totally redo the layout\"\\n    ]\\n  }\\n]\\n',\n",
              "  'output': '\\n\"work\": [\\n  {\\n    \"highlights\": [\\n      \"Commissioned to design and paint large-scale murals for local businesses, incorporating custom themes and branding\",\\n      \"Produced digital illustrations for e-commerce clients, enhancing their visual identity across web and social media\",\\n      \"Adapted quickly to client feedback by redesigning a complete layout under a tight deadline, meeting final approval within 24 hours\"\\n    ]\\n  }\\n]\\n'},\n",
              " {'input': '\\n\"work\": [\\n  {\\n    \"highlights\": [\\n      \"Made a small game in Unity for a class project with 3 friends — I did most of the level design\",\\n      \"We didn’t use any assets at first but then added some from the Unity store\",\\n      \"Had to fix some physics bugs that made the player get stuck\"\\n    ]\\n  }\\n]\\n',\n",
              "  'output': '\\n\"work\": [\\n  {\\n    \"highlights\": [\\n      \"Led level design for a Unity-based indie game developed in a team of four, emphasizing gameplay pacing and challenge balance\",\\n      \"Integrated third-party assets to enhance visual appeal while maintaining design consistency\",\\n      \"Diagnosed and resolved critical player movement bugs in Unity physics engine, improving overall user experience\"\\n    ]\\n  }\\n]\\n'}]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RESUME_TEMPLATES[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2eecd3a6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(RESUME_TEMPLATES)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25ef4e81",
      "metadata": {
        "id": "25ef4e81",
        "papermill": {
          "duration": 0.021487,
          "end_time": "2023-11-07T23:40:11.748796",
          "exception": false,
          "start_time": "2023-11-07T23:40:11.727309",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# CREATE THE DOCUMENT FROM THE DATAFRAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4c6f1238",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:11.793285Z",
          "iopub.status.busy": "2023-11-07T23:40:11.792911Z",
          "iopub.status.idle": "2023-11-07T23:40:12.353535Z",
          "shell.execute_reply": "2023-11-07T23:40:12.352343Z"
        },
        "id": "4c6f1238",
        "papermill": {
          "duration": 0.585876,
          "end_time": "2023-11-07T23:40:12.35627",
          "exception": false,
          "start_time": "2023-11-07T23:40:11.770394",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "78614daa",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:12.444219Z",
          "iopub.status.busy": "2023-11-07T23:40:12.443484Z",
          "iopub.status.idle": "2023-11-07T23:40:12.449168Z",
          "shell.execute_reply": "2023-11-07T23:40:12.447976Z"
        },
        "id": "78614daa",
        "papermill": {
          "duration": 0.030632,
          "end_time": "2023-11-07T23:40:12.451276",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.420644",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Convert your JSON list to LangChain Documents\n",
        "\n",
        "import json\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=json.dumps(item, indent=2) # Store the full object as JSON string\n",
        "    )\n",
        "    for item in RESUME_TEMPLATES\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "948950f7",
      "metadata": {
        "_kg_hide-output": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:12.700437Z",
          "iopub.status.busy": "2023-11-07T23:40:12.699647Z",
          "iopub.status.idle": "2023-11-07T23:40:12.759691Z",
          "shell.execute_reply": "2023-11-07T23:40:12.758871Z"
        },
        "id": "948950f7",
        "outputId": "9b1ccdff-c919-4cc7-a9f3-205f2228d494",
        "papermill": {
          "duration": 0.10378,
          "end_time": "2023-11-07T23:40:12.780315",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.676535",
          "status": "completed"
        },
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='{\\n  \"input\": \"\\\\n\\\\\"work\\\\\": [\\\\n  {\\\\n    \\\\\"highlights\\\\\": [\\\\n      \\\\\"Painted murals for a few local cafes \\\\u2014 they gave me free reign on design\\\\\",\\\\n      \\\\\"Also made digital illustrations for some small online businesses\\\\\",\\\\n      \\\\\"One client asked for revisions last-minute and I had to totally redo the layout\\\\\"\\\\n    ]\\\\n  }\\\\n]\\\\n\",\\n  \"output\": \"\\\\n\\\\\"work\\\\\": [\\\\n  {\\\\n    \\\\\"highlights\\\\\": [\\\\n      \\\\\"Commissioned to design and paint large-scale murals for local businesses, incorporating custom themes and branding\\\\\",\\\\n      \\\\\"Produced digital illustrations for e-commerce clients, enhancing their visual identity across web and social media\\\\\",\\\\n      \\\\\"Adapted quickly to client feedback by redesigning a complete layout under a tight deadline, meeting final approval within 24 hours\\\\\"\\\\n    ]\\\\n  }\\\\n]\\\\n\"\\n}'),\n",
              " Document(page_content='{\\n  \"input\": \"\\\\n\\\\\"work\\\\\": [\\\\n  {\\\\n    \\\\\"highlights\\\\\": [\\\\n      \\\\\"Made a small game in Unity for a class project with 3 friends \\\\u2014 I did most of the level design\\\\\",\\\\n      \\\\\"We didn\\\\u2019t use any assets at first but then added some from the Unity store\\\\\",\\\\n      \\\\\"Had to fix some physics bugs that made the player get stuck\\\\\"\\\\n    ]\\\\n  }\\\\n]\\\\n\",\\n  \"output\": \"\\\\n\\\\\"work\\\\\": [\\\\n  {\\\\n    \\\\\"highlights\\\\\": [\\\\n      \\\\\"Led level design for a Unity-based indie game developed in a team of four, emphasizing gameplay pacing and challenge balance\\\\\",\\\\n      \\\\\"Integrated third-party assets to enhance visual appeal while maintaining design consistency\\\\\",\\\\n      \\\\\"Diagnosed and resolved critical player movement bugs in Unity physics engine, improving overall user experience\\\\\"\\\\n    ]\\\\n  }\\\\n]\\\\n\"\\n}')]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(documents[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82937c96",
      "metadata": {
        "id": "82937c96",
        "papermill": {
          "duration": 0.026601,
          "end_time": "2023-11-07T23:40:12.833936",
          "exception": false,
          "start_time": "2023-11-07T23:40:12.807335",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Creating the embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "779e3387",
      "metadata": {
        "id": "779e3387",
        "papermill": {
          "duration": 0.03243,
          "end_time": "2023-11-07T23:40:13.245472",
          "exception": false,
          "start_time": "2023-11-07T23:40:13.213042",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "We load the library to create the pre trained model from HuggingFace to create the embeddings from sentences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7fa973ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:13.31152Z",
          "iopub.status.busy": "2023-11-07T23:40:13.310846Z",
          "iopub.status.idle": "2023-11-07T23:40:31.996557Z",
          "shell.execute_reply": "2023-11-07T23:40:31.995022Z"
        },
        "id": "7fa973ac",
        "outputId": "0898af45-3e70-47cb-cd07-859afbe1d043",
        "papermill": {
          "duration": 18.721786,
          "end_time": "2023-11-07T23:40:31.999291",
          "exception": false,
          "start_time": "2023-11-07T23:40:13.277505",
          "status": "completed"
        },
        "scrolled": true,
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ebengunadi/anaconda3/envs/grids-resume/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea58c45e",
      "metadata": {
        "id": "ea58c45e",
        "papermill": {
          "duration": 0.034795,
          "end_time": "2023-11-07T23:40:32.069162",
          "exception": false,
          "start_time": "2023-11-07T23:40:32.034367",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Creating the Index With Chroma\n",
        "Here we are creating the index of embeddings. Using the document, and the embedding function created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b7c8b44d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "eadc6d53",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-11-07T23:40:32.142168Z",
          "iopub.status.busy": "2023-11-07T23:40:32.140958Z",
          "iopub.status.idle": "2023-11-07T23:40:40.614344Z",
          "shell.execute_reply": "2023-11-07T23:40:40.613017Z"
        },
        "id": "eadc6d53",
        "papermill": {
          "duration": 8.512528,
          "end_time": "2023-11-07T23:40:40.616895",
          "exception": false,
          "start_time": "2023-11-07T23:40:32.104367",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "chroma_db = Chroma.from_documents(\n",
        "    documents, # using the entire document \n",
        "    embedding_function\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c83a8eca",
      "metadata": {
        "id": "c83a8eca",
        "papermill": {
          "duration": 0.0364,
          "end_time": "2023-11-07T23:42:17.696923",
          "exception": false,
          "start_time": "2023-11-07T23:42:17.660523",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Query documents from Vector DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b32685b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "query_1 = \"python data analysis visualization\"\n",
        "query_2 = \"nlp data analysis\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5ad8b348",
      "metadata": {},
      "outputs": [],
      "source": [
        "results_1 = chroma_db.similarity_search(query_1, k=1)\n",
        "results_2 = chroma_db.similarity_search(query_2, k=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0ad8c784",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='{\n",
            "  \"input\": \"\\n\\\"work\\\": [\\n  {\\n    \\\"highlights\\\": [\\n      \\\"Worked on this project at my internship where we had to clean a ton of messy sales data \\u2014 I wrote a few scripts in Python to fix formatting and missing stuff\\\",\\n      \\\"I also helped make some visuals in Tableau to show trends to the marketing team\\\",\\n      \\\"At one point, we had a bug that was breaking everything \\u2014 I figured out it was due to mismatched date formats\\\"\\n    ]\\n  }\\n]\\n\",\n",
            "  \"output\": \"\\n\\\"work\\\": [\\n  {\\n    \\\"highlights\\\": [\\n      \\\"Developed Python scripts for data cleaning and transformation, reducing manual data wrangling time by 40%\\\",\\n      \\\"Created interactive Tableau dashboards to visualize sales trends and support marketing decision-making\\\",\\n      \\\"Identified and resolved critical data pipeline issue related to inconsistent date formats, ensuring report accuracy\\\"\\n    ]\\n  }\\n]\\n\"\n",
            "}'\n"
          ]
        }
      ],
      "source": [
        "print(results_1[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0f501e85",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"input\": \"\\n\\\"work\\\": [\\n  {\\n    \\\"highlights\\\": [\\n      \\\"Worked on this project at my internship where we had to clean a ton of messy sales data \\u2014 I wrote a few scripts in Python to fix formatting and missing stuff\\\",\\n      \\\"I also helped make some visuals in Tableau to show trends to the marketing team\\\",\\n      \\\"At one point, we had a bug that was breaking everything \\u2014 I figured out it was due to mismatched date formats\\\"\\n    ]\\n  }\\n]\\n\",\n",
            "  \"output\": \"\\n\\\"work\\\": [\\n  {\\n    \\\"highlights\\\": [\\n      \\\"Developed Python scripts for data cleaning and transformation, reducing manual data wrangling time by 40%\\\",\\n      \\\"Created interactive Tableau dashboards to visualize sales trends and support marketing decision-making\\\",\\n      \\\"Identified and resolved critical data pipeline issue related to inconsistent date formats, ensuring report accuracy\\\"\\n    ]\\n  }\\n]\\n\"\n",
            "}\n",
            "{\n",
            "  \"input\": \"\\n      \\\"work\\\": [\\n        {\\n          \\\"highlights\\\": [\\n           \\\"I messed around with some Twitter data for a research assistant gig \\u2014 used tweepy to pull tweets and tried to do some basic sentiment stuff\\\",\\n            \\\"My advisor wanted to see if we could find anything about public opinion shifts during a product launch\\\",\\n            \\\"I didn\\u2019t know much NLP but figured out how to use NLTK and TextBlob after watching some YouTube videos\\\"\\n          ]\\n        }\\n      ]\",\n",
            "  \"output\": \"\\n      \\\"work\\\": [\\n        {\\n          \\\"highlights\\\": [\\n            \\\"Collected and analyzed Twitter data using Tweepy and NLP libraries (NLTK, TextBlob) to study sentiment around product launches\\\",\\n            \\\"Performed sentiment analysis on thousands of tweets to detect public opinion shifts during a high-profile event\\\",\\n            \\\"Delivered insights that contributed to a research paper on real-time consumer behavior tracking via social media\\\"\\n          ]\\n        }\\n      ]\\n    \"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "results_1_json = json.loads(results_1[0].page_content)\n",
        "results_2_json = json.loads(results_2[0].page_content)\n",
        "print(json.dumps(results_1_json, indent=2))\n",
        "print(json.dumps(results_2_json, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b94d0ddc",
      "metadata": {},
      "source": [
        "# Payload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4232f9ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"input\": \"\\n\\\"work\\\": [\\n  {\\n    \\\"highlights\\\": [\\n      \\\"Worked on this project at my internship where we had to clean a ton of messy sales data \\u2014 I wrote a few scripts in Python to fix formatting and missing stuff\\\",\\n      \\\"I also helped make some visuals in Tableau to show trends to the marketing team\\\",\\n      \\\"At one point, we had a bug that was breaking everything \\u2014 I figured out it was due to mismatched date formats\\\"\\n    ]\\n  }\\n]\\n\",\n",
            "    \"output\": \"\\n\\\"work\\\": [\\n  {\\n    \\\"highlights\\\": [\\n      \\\"Developed Python scripts for data cleaning and transformation, reducing manual data wrangling time by 40%\\\",\\n      \\\"Created interactive Tableau dashboards to visualize sales trends and support marketing decision-making\\\",\\n      \\\"Identified and resolved critical data pipeline issue related to inconsistent date formats, ensuring report accuracy\\\"\\n    ]\\n  }\\n]\\n\"\n",
            "  },\n",
            "  {\n",
            "    \"input\": \"\\n      \\\"work\\\": [\\n        {\\n          \\\"highlights\\\": [\\n           \\\"I messed around with some Twitter data for a research assistant gig \\u2014 used tweepy to pull tweets and tried to do some basic sentiment stuff\\\",\\n            \\\"My advisor wanted to see if we could find anything about public opinion shifts during a product launch\\\",\\n            \\\"I didn\\u2019t know much NLP but figured out how to use NLTK and TextBlob after watching some YouTube videos\\\"\\n          ]\\n        }\\n      ]\",\n",
            "    \"output\": \"\\n      \\\"work\\\": [\\n        {\\n          \\\"highlights\\\": [\\n            \\\"Collected and analyzed Twitter data using Tweepy and NLP libraries (NLTK, TextBlob) to study sentiment around product launches\\\",\\n            \\\"Performed sentiment analysis on thousands of tweets to detect public opinion shifts during a high-profile event\\\",\\n            \\\"Delivered insights that contributed to a research paper on real-time consumer behavior tracking via social media\\\"\\n          ]\\n        }\\n      ]\\n    \"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# return results_1_json, results_2_json as a list\n",
        "\n",
        "results = [\n",
        "    results_1_json,\n",
        "    results_2_json\n",
        "]\n",
        "\n",
        "print(json.dumps(results, indent=2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "grids-resume",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 301.368093,
      "end_time": "2023-11-07T23:43:39.05917",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-11-07T23:38:37.691077",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
